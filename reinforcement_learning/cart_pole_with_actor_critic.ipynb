{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "import gymnasium\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.l1 = nn.Linear(4, 25)\n",
    "        self.l2 = nn.Linear(25, 50)\n",
    "        self.actor_lin1 = nn.Linear(50, 2)\n",
    "        self.l3 = nn.Linear(50, 25)\n",
    "        self.critic_lin1 = nn.Linear(25, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.normalize(x, dim=0)\n",
    "        y = F.relu(self.l1(x))\n",
    "        y = F.relu(self.l2(y))\n",
    "        actor = F.log_softmax(self.actor_lin1(y), dim=0)\n",
    "        c = F.relu(self.l3(y.detach()))\n",
    "        critic = torch.tanh(self.critic_lin1(c))\n",
    "        return actor, critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(worker_env, worker_model):\n",
    "    state = torch.from_numpy(worker_env.env.state).float()\n",
    "    values, logprobs, rewards = [], [], []\n",
    "    done = False\n",
    "    j = 0\n",
    "    while (not done):\n",
    "        j += 1\n",
    "        policy, value = worker_model(state)\n",
    "        values.append(value)\n",
    "        logits = policy.view(-1)\n",
    "        action_dist = torch.distributions.Categorical(logits=logits)\n",
    "        action = action_dist.sample()\n",
    "        logprob_ = policy.view(-1)[action]\n",
    "        logprobs.append(logprob_)\n",
    "        state_, _, done, truncated, info = worker_env.step(action.detach().numpy())\n",
    "        state = torch.from_numpy(state_).float()\n",
    "\n",
    "        if done:\n",
    "            reward = -10\n",
    "            worker_env.reset()\n",
    "        else:\n",
    "            reward = 1.0\n",
    "        rewards.append(reward)\n",
    "\n",
    "    return values, logprobs, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(worker_opt, values, logprobs, rewards, clc=0.1, gamma=0.95):\n",
    "    # reverse the order of the rewards, logprobs and values\n",
    "    # .view(-1) is called to make sure that they are flat\n",
    "    rewards = torch.Tensor(rewards).flip(dims=(0,)).view(-1)\n",
    "    logprobs = torch.stack(logprobs).flip(dims=(0,)).view(-1)\n",
    "    values = torch.stack(values).flip(dims=(0,)).view(-1)\n",
    "    Returns = []\n",
    "    ret_ = torch.Tensor([0])\n",
    "\n",
    "    for r in range(rewards.shape[0]):\n",
    "        ret_ = rewards[r] + gamma * ret_\n",
    "        Returns.append(ret_)\n",
    "    Returns = torch.stack(Returns).view(-1)\n",
    "    Returns = F.normalize(Returns, dim=0)\n",
    "\n",
    "    # we need to detach the values tensor from the graph to prevent\n",
    "    # back propagating through the critic head\n",
    "    actor_loss = -1 * logprobs * (Returns - values.detach())\n",
    "    critic_loss = torch.pow(values - Returns, 2)\n",
    "    # sum the actor and critic losses to get an overall loss\n",
    "    # we scale down the critic loss because we want the actor to learn\n",
    "    # faster than the critic\n",
    "    loss = actor_loss.sum() + clc * critic_loss.sum()\n",
    "    loss.backward()\n",
    "    worker_opt.step()\n",
    "    return actor_loss, critic_loss, len(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the main training loop\n",
    "def worker(t, worker_model, counter, params):\n",
    "    worker_env = gymnasium.make('CartPole-v1')\n",
    "    worker_env.reset()\n",
    "    worker_opt = optim.Adam(lr=1e-4, params=worker_model.parameters())\n",
    "    worker_opt.zero_grad()\n",
    "\n",
    "    for i in range(params['epochs']):\n",
    "        worker_opt.zero_grad()\n",
    "        values, logprobs, rewards = run_episode(worker_env, worker_model)\n",
    "        actor_loss, critic_loss, eplen = update_params(worker_opt, values, logprobs, rewards)\n",
    "        counter.value = counter.value + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/bifnudozhao/miniconda3/envs/tensorflow/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/bifnudozhao/miniconda3/envs/tensorflow/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'worker' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/bifnudozhao/miniconda3/envs/tensorflow/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/bifnudozhao/miniconda3/envs/tensorflow/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'worker' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/bifnudozhao/miniconda3/envs/tensorflow/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/bifnudozhao/miniconda3/envs/tensorflow/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'worker' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/bifnudozhao/miniconda3/envs/tensorflow/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/bifnudozhao/miniconda3/envs/tensorflow/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'worker' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/bifnudozhao/miniconda3/envs/tensorflow/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/bifnudozhao/miniconda3/envs/tensorflow/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'worker' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/bifnudozhao/miniconda3/envs/tensorflow/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/bifnudozhao/miniconda3/envs/tensorflow/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'worker' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/bifnudozhao/miniconda3/envs/tensorflow/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/bifnudozhao/miniconda3/envs/tensorflow/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'worker' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    MasterNode = ActorCritic()\n",
    "    MasterNode.share_memory()\n",
    "    processes = []\n",
    "    params = {\n",
    "        'epochs': 1000,\n",
    "        'n_workers': 7,\n",
    "    }\n",
    "    \n",
    "    counter = mp.Value('i', 0)\n",
    "    for i in range(params['n_workers']):\n",
    "        p = mp.Process(target=worker, args=(i, MasterNode, counter, params))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "    \n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    \n",
    "    for p in processes:\n",
    "        p.terminate()\n",
    "    \n",
    "    print(counter.value, processes[1].exitcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
