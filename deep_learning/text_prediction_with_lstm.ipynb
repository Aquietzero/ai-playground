{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length:  600893\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "path = keras.utils.get_file(\n",
    "    '/Users/bifnudozhao/Projects/ai-playground/datasets/nietzshe.txt',\n",
    "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt'\n",
    ")\n",
    "\n",
    "text = open(path).read().lower()\n",
    "print('Corpus length: ', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取语料之后，先使用 `maxlen` 产生相互重叠的序列，用 one-hot 编码，然后将它们组织为一个形状为 `(sequences, maxlen, unique_charaters)` 的 numpy 数组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences:  200278\n",
      "Unique characters:  57\n"
     ]
    }
   ],
   "source": [
    "maxlen = 60\n",
    "step = 3 # sample a new sequence every three characters\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "\n",
    "print('Number of sequences: ', len(sentences))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('Unique characters: ', len(chars))\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=bool)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(tf.compat.v1.keras.layers.CuDNNLSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(layers.Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.legacy.RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-06 11:13:45.693781: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1565/1565 [==============================] - 35s 20ms/step - loss: 1.9554\n",
      "--- Generateing with seed:   heaven of clear, wicked spirituality,\n",
      "which, from above, wo\n",
      "----- temperature:  0.2\n",
      " heaven of clear, wicked spirituality,\n",
      "which, from above, would in the deation of the seem from the sense and such the called and moral sould and in the consequents and the seems and in the sense and and be seem from the delight of the seem the understand in the seems and the seals and the consequents of the seems and the sender and in the seems the sense of the seems and the seem the realing of the sense of the sense and in the allower called and in the s----- temperature:  0.5\n",
      "he sense of the sense and in the allower called and in the sacred and say, which the course of may the precessation. the deleation of the all one of seems in the seched. and it has and the compatised preciles the faith in a relects for the same in the sense of the deflain in the great and prease in the a faidity of the and the man which religion, all the a decesss of the compired of an all in a could and means and such as and in the woral being and the del----- temperature:  1.0\n",
      "uld and means and such as and in the woral being and the delural an when reaptoor\n",
      "ghelily they saking of plandtem,\n",
      "seasemest there\n",
      "and rempare lof been\n",
      "successes of puologoddun to they, is may, and say in the lightly, \"of the is decelf of distrust, that faened.\n",
      "\n",
      "1um. the reveligion of menfind--gone ourself?\n",
      "which a a trutueme dorman\n",
      "\n",
      "\"everctation. he on ulleupness and dis\n",
      "our in them, as ame has attively, in actors an \"whetilione that make melard the germa----- temperature:  1.2\n",
      "ttively, in actors an \"whetilione that make melard the german sporis of gotm. thereives of arilwhe faltrve\n",
      "cal. foo\n",
      "imant\n",
      "asing sympation, dusk \"arilnt inemo.\"?\n",
      "\n",
      "p.\n",
      "\n",
      "ura\n",
      "to by it lest in which \"good neels, exylafdly anotimicm. valle,, expectively in the poentialle, pulsd, b\"reard anothing,\n",
      "i thore\n",
      "af\n",
      "a taast general, immaybdetors)??\n",
      "\n",
      "\n",
      "12.. theuta impoturely and sucht: \"usin be a notred?  it is inslay, the orgoos\n",
      "drymuld in the unsace and this rouw? obicatiepoch 2\n",
      "1565/1565 [==============================] - 33s 21ms/step - loss: 1.6114\n",
      "--- Generateing with seed:   the sympathy which each beholder\n",
      "manifests is a consolation\n",
      "----- temperature:  0.2\n",
      " the sympathy which each beholder\n",
      "manifests is a consolation of the stand the present the contrary of the mankind and something sought and the present the denounce of the senses of the stand of the contrary and the command the standing and the spirit of the profound the morality of the consequence of the more the command and the contrary and the consequent of the command of the mankind the command and the contrary of the present the contrary and the contra----- temperature:  0.5\n",
      " and the contrary of the present the contrary and the contrary and themselves and the consequence which the highest not perhaps a tooble charm and something the intelling\n",
      "the only as a not mankind their denerate that the present to contemps must they one of the modictical intention of an also something in have life--for once to the command of the being of the conceptions of the gradument of the still to the beings and will of the expedsion and there as the----- temperature:  1.0\n",
      "ill to the beings and will of the expedsion and there as the "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/bifnudozhao/Projects/ai-playground/deep_learning/text_prediction_with_lstm.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bifnudozhao/Projects/ai-playground/deep_learning/text_prediction_with_lstm.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfor\u001b[39;00m t, char \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(generated_text):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bifnudozhao/Projects/ai-playground/deep_learning/text_prediction_with_lstm.ipynb#W6sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     sampled[\u001b[39m0\u001b[39m, t, char_indices[char]] \u001b[39m=\u001b[39m \u001b[39m1.\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/bifnudozhao/Projects/ai-playground/deep_learning/text_prediction_with_lstm.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(sampled, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bifnudozhao/Projects/ai-playground/deep_learning/text_prediction_with_lstm.ipynb#W6sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m next_index \u001b[39m=\u001b[39m sample(preds, temperature)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bifnudozhao/Projects/ai-playground/deep_learning/text_prediction_with_lstm.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m next_char \u001b[39m=\u001b[39m chars[next_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/engine/training.py:2596\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2587\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m   2588\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   2589\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2590\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2593\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m   2594\u001b[0m         )\n\u001b[0;32m-> 2596\u001b[0m data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mget_data_handler(\n\u001b[1;32m   2597\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m   2598\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   2599\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps,\n\u001b[1;32m   2600\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m   2601\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m   2602\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   2603\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   2604\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   2605\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2606\u001b[0m     steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution,\n\u001b[1;32m   2607\u001b[0m )\n\u001b[1;32m   2609\u001b[0m \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   2610\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/engine/data_adapter.py:1688\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorExactEvalDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1687\u001b[0m     \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 1688\u001b[0m \u001b[39mreturn\u001b[39;00m DataHandler(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/engine/data_adapter.py:1292\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[1;32m   1289\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution \u001b[39m=\u001b[39m steps_per_execution\n\u001b[1;32m   1291\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1292\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[1;32m   1293\u001b[0m     x,\n\u001b[1;32m   1294\u001b[0m     y,\n\u001b[1;32m   1295\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   1296\u001b[0m     steps\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   1297\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs \u001b[39m-\u001b[39;49m initial_epoch,\n\u001b[1;32m   1298\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1299\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   1300\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1301\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1302\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1303\u001b[0m     distribution_strategy\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49mget_strategy(),\n\u001b[1;32m   1304\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1305\u001b[0m     pss_evaluation_shards\u001b[39m=\u001b[39;49mpss_evaluation_shards,\n\u001b[1;32m   1306\u001b[0m )\n\u001b[1;32m   1308\u001b[0m strategy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\n\u001b[1;32m   1310\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/keras/src/engine/data_adapter.py:314\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[39mreturn\u001b[39;00m indices\n\u001b[1;32m    309\u001b[0m \u001b[39m# We prefetch a single element. Computing large permutations can take\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39m# quite a while so we don't want to wait for prefetching over an epoch\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[39m# boundary to trigger the next permutation. On the other hand, too many\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[39m# simultaneous shuffles can contend on a hardware level and degrade all\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[39m# performance.\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m indices_dataset \u001b[39m=\u001b[39m indices_dataset\u001b[39m.\u001b[39;49mmap(permutation)\u001b[39m.\u001b[39mprefetch(\u001b[39m1\u001b[39m)\n\u001b[1;32m    316\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mslice_batch_indices\u001b[39m(indices):\n\u001b[1;32m    317\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Convert a Tensor of indices into a dataset of batched indices.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \n\u001b[1;32m    319\u001b[0m \u001b[39m    This step can be accomplished in several ways. The most natural is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[39m      A Dataset of batched indices.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:2268\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2264\u001b[0m \u001b[39m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2265\u001b[0m \u001b[39m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2266\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2267\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2268\u001b[0m \u001b[39mreturn\u001b[39;00m map_op\u001b[39m.\u001b[39;49m_map_v2(\n\u001b[1;32m   2269\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2270\u001b[0m     map_func,\n\u001b[1;32m   2271\u001b[0m     num_parallel_calls\u001b[39m=\u001b[39;49mnum_parallel_calls,\n\u001b[1;32m   2272\u001b[0m     deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[1;32m   2273\u001b[0m     name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/data/ops/map_op.py:37\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[39mif\u001b[39;00m deterministic \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m debug_mode\u001b[39m.\u001b[39mDEBUG_MODE:\n\u001b[1;32m     35\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39m`num_parallel_calls` argument is specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m   \u001b[39mreturn\u001b[39;00m _MapDataset(\n\u001b[1;32m     38\u001b[0m       input_dataset, map_func, preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m     39\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m   \u001b[39mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[1;32m     41\u001b[0m       input_dataset,\n\u001b[1;32m     42\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m       preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m       name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/data/ops/map_op.py:113\u001b[0m, in \u001b[0;36m_MapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39mStructuredFunctionWrapper(\n\u001b[1;32m    108\u001b[0m     map_func,\n\u001b[1;32m    109\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transformation_name(),\n\u001b[1;32m    110\u001b[0m     dataset\u001b[39m=\u001b[39minput_dataset,\n\u001b[1;32m    111\u001b[0m     use_legacy_function\u001b[39m=\u001b[39muse_legacy_function)\n\u001b[1;32m    112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m name\n\u001b[0;32m--> 113\u001b[0m variant_tensor \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49mmap_dataset(\n\u001b[1;32m    114\u001b[0m     input_dataset\u001b[39m.\u001b[39;49m_variant_tensor,  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    115\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_func\u001b[39m.\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs,\n\u001b[1;32m    116\u001b[0m     f\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_func\u001b[39m.\u001b[39;49mfunction,\n\u001b[1;32m    117\u001b[0m     use_inter_op_parallelism\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_use_inter_op_parallelism,\n\u001b[1;32m    118\u001b[0m     preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_preserve_cardinality,\n\u001b[1;32m    119\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_common_args)\n\u001b[1;32m    120\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(input_dataset, variant_tensor)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3471\u001b[0m, in \u001b[0;36mmap_dataset\u001b[0;34m(input_dataset, other_arguments, f, output_types, output_shapes, use_inter_op_parallelism, preserve_cardinality, metadata, name)\u001b[0m\n\u001b[1;32m   3469\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m   3470\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3471\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m   3472\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mMapDataset\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, input_dataset, other_arguments, \u001b[39m\"\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m, f,\n\u001b[1;32m   3473\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39moutput_types\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_types, \u001b[39m\"\u001b[39;49m\u001b[39moutput_shapes\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_shapes,\n\u001b[1;32m   3474\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39muse_inter_op_parallelism\u001b[39;49m\u001b[39m\"\u001b[39;49m, use_inter_op_parallelism,\n\u001b[1;32m   3475\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mpreserve_cardinality\u001b[39;49m\u001b[39m\"\u001b[39;49m, preserve_cardinality, \u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m, metadata)\n\u001b[1;32m   3476\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   3477\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "for epoch in range(1, 61):\n",
    "    print('epoch', epoch)\n",
    "    # fits the model for one iteration on the data\n",
    "    model.fit(x, y, batch_size=128, epochs=1)\n",
    "\n",
    "    # only outputs temperal result at epoch 10, 20, 30, 40, 50, 60\n",
    "    if epoch % 10 != 0: continue\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index:start_index + maxlen]\n",
    "    print('--- Generateing with seed: ', generated_text)\n",
    "\n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- temperature: ', temperature)\n",
    "        sys.stdout.write(generated_text)\n",
    "\n",
    "        # generates 400 characters, starting from the seed text\n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = chars[next_index]\n",
    "\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "\n",
    "            sys.stdout.write(next_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
